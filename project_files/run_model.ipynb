{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "%run feature_reductions.ipynb\n",
    "%run join_and_normalize.ipynb\n",
    "%run modeling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label name is 'Group' for the HIV dataset\n",
    "\n",
    "def run_entire_model(osu_files, \n",
    "                     tax_files, \n",
    "                     meta_file, \n",
    "                     norm_type,\n",
    "                     ncomp,\n",
    "                     levelup, \n",
    "                     groups,\n",
    "                     feat_reduction, \n",
    "                     test_frac, \n",
    "                     model,\n",
    "                     upsample,\n",
    "                     plot_pca,\n",
    "                     plot_lc,\n",
    "                     plot_ab_comp):\n",
    "    \n",
    "    osu_df = join_osus(osu_files,norm_type)\n",
    "    \n",
    "    meta_df = get_labels(meta_file)\n",
    "    osu_df = join_osu_with_labels(osu_df,meta_df)\n",
    "    tax_df = join_taxonomy(tax_files)\n",
    "    \n",
    "    pair_df = select_groups(osu_df,groups)\n",
    "    \n",
    "    if upsample == True:\n",
    "        groups = pair_df.Group.unique()\n",
    "        g0_vals = pair_df.loc[pair_df['Group'] == groups[0]]['Group'].value_counts()\n",
    "        g1_vals = pair_df.loc[pair_df['Group'] == groups[1]]['Group'].value_counts()\n",
    "        \n",
    "        if g0_vals[0] > g1_vals[0]:\n",
    "            df_majority = pair_df[pair_df.Group==groups[0]]\n",
    "            df_minority = pair_df[pair_df.Group==groups[1]]\n",
    "            imbalanced=True\n",
    "            maj_num = g0_vals[0]\n",
    "        elif g0_vals[0] < g1_vals[0]:\n",
    "            df_majority = pair_df[pair_df.Group==groups[1]]\n",
    "            df_minority = pair_df[pair_df.Group==groups[0]]\n",
    "            imbalanced=True\n",
    "            maj_num = g1_vals[0]\n",
    "        else:\n",
    "            imbalanced=False\n",
    "            \n",
    "        if imbalanced==True:\n",
    "            df_minority_upsampled = resample(df_minority, \n",
    "                                             replace=True,     \n",
    "                                             n_samples=maj_num,    \n",
    "                                             random_state=42)\n",
    "            \n",
    "            pair_df = pd.concat([df_majority, df_minority_upsampled])\n",
    "    \n",
    "    if levelup != None:\n",
    "        pair_df = make_df_up_level(pair_df,tax_df,levelup,norm_type)\n",
    "    \n",
    "    an_df = pair_df\n",
    "    \n",
    "    feats = None\n",
    "    if feat_reduction =='svd':\n",
    "        X,Y,labels = SVD_truncate(pair_df,ncomp)\n",
    "    elif feat_reduction =='zscore':\n",
    "        cutoff = 0.001\n",
    "        plot_cutoff = 0.3\n",
    "        X,Y,labels,feats = make_dataset_zscore(pair_df, ncomp,cutoff,plot_cutoff)\n",
    "    elif feat_reduction =='corr':\n",
    "        X,Y,labels,feats = feature_from_correlation(pair_df,ncomp)\n",
    "    elif feat_reduction =='diff':\n",
    "        cutoff=0.001\n",
    "        X,Y,labels,feats = make_dataset_osu_diff(pair_df, ncomp,cutoff)\n",
    "    elif feat_reduction =='top':\n",
    "        X,Y,labels,feats = get_top_osu_ids(pair_df, ncomp)\n",
    "    elif feat_reduction == None:\n",
    "        cutoff=0.001\n",
    "        X,Y,labels,feats = make_dataset(pair_df,cutoff)\n",
    "        \n",
    "    print(\"Comparing the following groups:\",labels)\n",
    "        \n",
    "    print(feats)\n",
    "    if feats !=None:\n",
    "        print(\"Top features:\",feats)\n",
    "        \n",
    "    if plot_pca == True:\n",
    "        if feat_reduction == 'svd':\n",
    "            X1 = X[:, 0]\n",
    "            X2 = X[:, 1]\n",
    "        else: \n",
    "            X_PCA = PCA(n_components=2, random_state=42).fit_transform(np.array(X))\n",
    "            X1 = X_PCA[:, 0]\n",
    "            X2 = X_PCA[:, 1]\n",
    "        c=np.array(Y)\n",
    "        colors = np.where(c == 0, 'r', 'k')\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(X1, X2, c=colors)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    \n",
    "    seed = 20\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size=test_frac,\n",
    "                                                    random_state=seed)\n",
    "    \n",
    "    \n",
    "    if model == 'lg':\n",
    "        print('-'*50)\n",
    "        print('Logistic Regression')\n",
    "        result_table = opt_log_reg(X_train,y_train,X_test,y_test,labels)\n",
    "    elif model == 'rf':\n",
    "        print('-'*50)\n",
    "        print('Random Forest')\n",
    "        result_table = opt_random_forest(X_train,y_train,X_test,y_test,labels)\n",
    "    elif model == 'xg':\n",
    "        print('-'*50)\n",
    "        print('XG Boost')\n",
    "        opt_xgboost(X_train,y_train,X_test,y_test,labels)\n",
    "    elif model == 'all':\n",
    "        print('-'*50)\n",
    "        print('Logistic Regression')\n",
    "        opt_log_reg(X_train,y_train,X_test,y_test,labels)\n",
    "        print('-'*50)\n",
    "        print('Random Forest')\n",
    "        opt_random_forest(X_train,y_train,X_test,y_test,labels)\n",
    "        print('-'*50)\n",
    "        print('XG Boost')\n",
    "        opt_xgboost(X_train,y_train,X_test,y_test,labels)\n",
    "        \n",
    "    if plot_ab_comp == True:\n",
    "        if feats == None:\n",
    "            print(\"Plotting abundance only applicable when zscore, diff, corr feature reduction used.\")\n",
    "        elif len(feats) > 20:\n",
    "            print(\"Too many features to plot effectively.\")\n",
    "        else:\n",
    "            IDs = feats\n",
    "            abundance_comparison(an_df,IDs,norm_type)\n",
    "        \n",
    "    if plot_lc == True:\n",
    "\n",
    "        title = \"Learning Curve for Logistic Regression\"\n",
    "        # Cross validation with 100 iterations to get smoother mean test and train\n",
    "        # score curves, each time with 20% data randomly selected as a validation set.\n",
    "        cv = ShuffleSplit(n_splits=100, test_size=test_frac, random_state=0)\n",
    "\n",
    "        estimator = LogisticRegression(random_state = 42, solver ='liblinear');\n",
    "        plot_learning_curve(estimator, title, X, Y, ylim=(0.0, 1.01), cv=cv, n_jobs=10)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
